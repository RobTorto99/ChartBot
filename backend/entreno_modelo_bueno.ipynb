{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roberto/Projects/ChartBot/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-01 00:13:05.263816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740784385.281563   27474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740784385.286991   27474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 00:13:05.305793: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "# AÃ±ade esto antes de cargar el modelo\n",
    "from unsloth import is_bfloat16_supported\n",
    "torch.set_default_dtype(torch.bfloat16 if is_bfloat16_supported() else torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:17<00:17, 17.19s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 9.77 GiB of which 76.88 MiB is free. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.53 GiB is allocated by PyTorch, and 13.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m# Carga el modelo con Unsloth (optimizado para entrenamiento)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mmodel, tokenizer = FastLanguageModel.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mmodel = AutoModelForCausalLM.from_pretrained(\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"unsloth/Qwen2.5-Coder-7B-Instruct\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#device_map=\"auto\"  # auto-detecta GPU y, si es necesario, hace offload a CPU/RAM\u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     85\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4224\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4214\u001b[0m         load_contexts\u001b[38;5;241m.\u001b[39mappend(tp_device)\n\u001b[1;32m   4216\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(load_contexts):\n\u001b[1;32m   4217\u001b[0m         (\n\u001b[1;32m   4218\u001b[0m             model,\n\u001b[1;32m   4219\u001b[0m             missing_keys,\n\u001b[1;32m   4220\u001b[0m             unexpected_keys,\n\u001b[1;32m   4221\u001b[0m             mismatched_keys,\n\u001b[1;32m   4222\u001b[0m             offload_index,\n\u001b[1;32m   4223\u001b[0m             error_msgs,\n\u001b[0;32m-> 4224\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4229\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m            \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4244\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4245\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4794\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4793\u001b[0m         fixed_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_fix_state_dict_keys_on_load(state_dict)\n\u001b[0;32m-> 4794\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4795\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4796\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfixed_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4797\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4800\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4801\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4802\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4803\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4804\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4805\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4806\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4807\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4808\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4810\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:875\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    873\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 875\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:226\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.create_quantized_param\u001b[0;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_bnb_supports_quant_storage_module:\n\u001b[1;32m    224\u001b[0m         param_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m--> 226\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParams4bit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_prequantized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquantized_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantized_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparam_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m param_value\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/ChartBot/venv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:278\u001b[0m, in \u001b[0;36mParams4bit.from_prequantized\u001b[0;34m(cls, data, quantized_stats, requires_grad, device, module, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_prequantized\u001b[39m(\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    277\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39m_make_subclass(\u001b[38;5;28mcls\u001b[39m, \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m requires_grad\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;241m=\u001b[39m QuantState\u001b[38;5;241m.\u001b[39mfrom_dict(qs_dict\u001b[38;5;241m=\u001b[39mquantized_stats, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 9.77 GiB of which 76.88 MiB is free. Including non-PyTorch memory, this process has 8.75 GiB memory in use. Of the allocated memory 8.53 GiB is allocated by PyTorch, and 13.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset, DatasetDict, Features, Value\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "max_seq_length = 1024 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",     \n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",                  # probar la normal\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",         # probar la version que sabe seguir instrucciones code\n",
    "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",     \n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "    \"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "    \"unsloth/Qwen2.5-Coder-3B-bnb-4bit\",\n",
    "    \"Qwen/Qwen2.5-Coder-3B-Instruct\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    \"unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit\",\n",
    "    \"Qwen/Qwen2.5-Coder-14B-Instruct\",\n",
    "    \"unsloth/Qwen2.5-Coder-14B-Instruct\"\n",
    "]\n",
    "\n",
    "# Configurar BitsAndBytes para cuantizaciÃ³n en 4 bits\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,       # Habilitar cuantizaciÃ³n en 4 bit\n",
    "    bnb_4bit_quant_type=\"nf4\",       # nf4 recomendado para entrenamiento\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Configurar cÃ¡lculos en float16\n",
    "    bnb_4bit_use_double_quant=True  # Usar doble cuantizaciÃ³n\n",
    ")\n",
    "\"\"\"\n",
    "# Nombre del modelo\n",
    "model_name = \"unsloth/Qwen2.5-Coder-7B-Instruct\"\n",
    "\n",
    "# Cargar el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Cargar el modelo con cuantizaciÃ³n\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    quantization_config=bnb_config,  # ConfiguraciÃ³n de BitsAndBytes\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Carga el modelo con Unsloth (optimizado para entrenamiento)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Qwen2.5-Coder-7B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=torch.bfloat16 if is_bfloat16_supported() else torch.float16,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-Coder-7B-Instruct\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",  # auto-detecta GPU y, si es necesario, hace offload a CPU/RAM\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True)\n",
    "\n",
    "\"\"\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit\",\n",
    "    quantization_config=bnb_config,\n",
    "    #device_map=\"auto\"  # auto-detecta GPU y, si es necesario, hace offload a CPU/RAM\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Qwen2.5-Coder-14B-Instruct-bnb-4bit\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.1.6 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,092,544 || all params: 7,625,709,056 || trainable%: 0.1323\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")\n",
    "-----------------------\n",
    "\n",
    "model = prepare_model_for_kbit_training(\n",
    "    model,\n",
    "    use_gradient_checkpointing=True, \n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 2,                  # Reduce a 2 (mÃ­nimo para mantener rendimiento)\n",
    "    lora_alpha = 8,         # Alpha = 4x el rank\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],  \n",
    "    lora_dropout = 0.1,     # Aumenta dropout para regularizaciÃ³n\n",
    "    use_gradient_checkpointing = \"unsloth\",  # Checkpointing optimizado\n",
    "    bias = \"none\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)  # AÃ±ade esto antes de aplicar LoRA\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config) \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Aplica la configuraciÃ³n LoRA de Unsloth\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,  # Aumentar rango QLoRA ver indicaciones de la formula\n",
    "    lora_alpha=32,\n",
    "    #target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1, \n",
    "    use_gradient_checkpointing=True,  # Mejor integrado que enable()\n",
    ")\n",
    "\n",
    "# Verifica parÃ¡metros entrenables\n",
    "model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt= \"\"\"Below is an instruction that give a prompt. Write a response that appropriately completes the request and gives you a visualization code and the corresponding explanation.\n",
    "\n",
    "### visualization _prompt:\n",
    "{}\n",
    "\n",
    "### visualization_code:\n",
    "{}\n",
    "\n",
    "### visualization_explanation:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 0\n",
    "dataset_2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples, tokenizer):\n",
    "    visualization_prompts = examples[\"visualization_prompt\"]\n",
    "    visualization_codes = examples[\"visualization_code\"]\n",
    "    visualization_explanations = examples['visualization_explanation']\n",
    "    \n",
    "    texts = []\n",
    "    EOS_TOKEN = tokenizer.eos_token  # Token de finalizaciÃ³n\n",
    "\n",
    "    for prompt, code_list, explanation in zip(visualization_prompts, visualization_codes, visualization_explanations):\n",
    "        # Manejar diferentes niveles de anidamiento\n",
    "        if isinstance(code_list, list):\n",
    "            # Aplanar si es una lista de listas\n",
    "            flattened_code_list = []\n",
    "            for item in code_list:\n",
    "                if isinstance(item, dict):\n",
    "                    flattened_code_list.append(item)\n",
    "                elif isinstance(item, list):\n",
    "                    for sub_item in item:\n",
    "                        if isinstance(sub_item, dict):\n",
    "                            flattened_code_list.append(sub_item)\n",
    "            # Extraer los cÃ³digos\n",
    "            html_codes = [code.get(\"html\", \"\") for code in flattened_code_list]\n",
    "            css_codes = [code.get(\"CSS\", \"\") for code in flattened_code_list]\n",
    "            js_codes = [code.get(\"JavaScript\", \"\") for code in flattened_code_list]\n",
    "            \n",
    "            html_code = \"\\n\".join(html_codes)\n",
    "            css_code = \"\\n\".join(css_codes)\n",
    "            js_code = \"\\n\".join(js_codes)\n",
    "        else:\n",
    "            html_code = \"\"\n",
    "            css_code = \"\"\n",
    "            js_code = \"\"\n",
    "        \n",
    "        # Formatear usando la plantilla `alpaca_prompt`\n",
    "        text = alpaca_prompt.format(\n",
    "            prompt,\n",
    "            f\"HTML:\\n{html_code}\\n\\nCSS:\\n{css_code}\\n\\nJavaScript:\\n{js_code}\",\n",
    "            explanation\n",
    "        ) + EOS_TOKEN  # AÃ±adir el token EOS al final de cada texto\n",
    "        \n",
    "        texts.append(text)\n",
    "\n",
    "    return {\"text\": texts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func_2(examples, tokenizer):\n",
    "    visualization_prompt = examples[\"visualization_prompt\"]\n",
    "    visualization_code = examples[\"visualization_code\"]      # Cadena de texto (JSON)\n",
    "    visualization_explanation = examples[\"visualization_explanation\"]\n",
    "\n",
    "    texts = []\n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "    for prompt, code, explanation in zip(visualization_prompt, visualization_code, visualization_explanation):\n",
    "        # Convertir el objeto visualization_code en una cadena JSON formateada (si es necesario)\n",
    "        try:\n",
    "            json.loads(code)\n",
    "            chart_options_str = code\n",
    "        except json.JSONDecodeError:\n",
    "            # Si no es un JSON vÃ¡lido, intenta convertirlo\n",
    "            chart_options_str = json.dumps(code, indent=4)\n",
    "\n",
    "        # Formatear usando la plantilla para los nuevos datos\n",
    "        text = alpaca_prompt.format(\n",
    "            prompt,\n",
    "            chart_options_str,  # Ahora la cadena JSON formateada\n",
    "            explanation\n",
    "        ) + EOS_TOKEN\n",
    "\n",
    "        texts.append(text)\n",
    "\n",
    "    return {\"text\": texts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"/home/roberto/Projects/ChartBot/dataset_test/\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['visualization_prompt', 'visualization_code', 'visualization_explanation'],\n",
      "        num_rows: 983\n",
      "    })\n",
      "})\n",
      "{'visualization_prompt': \"Create a Highcharts chartOptions object to render a 3D pie chart with the following specifications: Chart type: pie, Chart title: '3D Pie Chart Example', Axes and labels styling: Use a dark blue color (#003366) for the title and labels, with a font size of 14px for labels and 18px for the title. Data series: Include one series with the data [2, 4, 6, 1, 3]. Custom colors: Use a specific list of colors ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0', '#9966FF']. Additional configurations: Set the chart margins to 50px, use a light gray background (#F5F5F5), and enable the legend with a dark gray color (#333333).\", 'visualization_code': '{\"chart\": {\"backgroundColor\": \"#F5F5F5\", \"margin\": [50, 50, 50, 50]}, \"title\": {\"text\": \"3D Pie Chart Example\", \"style\": {\"color\": \"#003366\", \"fontSize\": \"18px\"}}, \"plotOptions\": {\"pie\": {\"depth\": 45, \"startAngle\": -90, \"endAngle\": 90, \"colors\": [\"#FF6384\", \"#36A2EB\", \"#FFCE56\", \"#4BC0C0\", \"#9966FF\"]}}, \"series\": [{\"data\": [2, 4, 6, 1, 3]}], \"legend\": {\"enabled\": true, \"itemStyle\": {\"color\": \"#333333\"}}, \"xAxis\": {\"labels\": {\"style\": {\"color\": \"#003366\", \"fontSize\": \"14px\"}}}, \"yAxis\": {\"labels\": {\"style\": {\"color\": \"#003366\", \"fontSize\": \"14px\"}}}}', 'visualization_explanation': \"The provided Highcharts chartOptions object is configured to render a 3D pie chart with specific visual customizations. The chart type is set to 'pie' with 3D options enabled, creating a 3D effect with an alpha angle of 25 degrees. The chart title is styled with a dark blue color and a larger font size, while the axes labels are also styled in dark blue with a smaller font size. The data series includes one series with the values [2, 4, 6, 1, 3], and custom colors are applied to each segment of the pie chart. Additional configurations include setting the chart background to light gray and adjusting the margins to 50px. The legend is enabled and styled with a dark gray color, enhancing the overall readability and visual appeal of the chart.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta a los archivos del dataset\n",
    "dataset_path = \"/home/roberto/Projects/ChartBot/dataset_test_2/*.json\"  # Ajusta la extensiÃ³n si es necesario\n",
    "\n",
    "# Paso 1: Leer y consolidar todos los archivos JSON\n",
    "data = []\n",
    "json_files = glob.glob(dataset_path)\n",
    "\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            # Asumiendo JSON estÃ¡ndar\n",
    "            entries = json.load(f)\n",
    "            if isinstance(entries, list):\n",
    "                data.extend(entries)\n",
    "            elif isinstance(entries, dict):\n",
    "                data.append(entries)\n",
    "            else:\n",
    "                print(f\"Formato desconocido en {file_path}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error al leer {file_path}: {e}\")\n",
    "\n",
    "# Paso 2: Verificar y transformar los datos\n",
    "for entry in data:\n",
    "    # Asegurarse de que todas las claves existan\n",
    "    if \"visualization_prompt\" not in entry:\n",
    "        entry[\"visualization_prompt\"] = \"\"\n",
    "    if \"visualization_code\" not in entry:\n",
    "        entry[\"visualization_code\"] = {}\n",
    "    if \"visualization_explanation\" not in entry:\n",
    "        entry[\"visualization_explanation\"] = \"\"\n",
    "    \n",
    "    # Convertir `visualization_code` a cadena JSON si es un dict o list\n",
    "    if isinstance(entry[\"visualization_code\"], (dict, list)):\n",
    "        entry[\"visualization_code\"] = json.dumps(entry[\"visualization_code\"])\n",
    "    else:\n",
    "        entry[\"visualization_code\"] = str(entry[\"visualization_code\"])\n",
    "    \n",
    "    # Asegurarse de que los demÃ¡s campos sean cadenas\n",
    "    entry[\"visualization_prompt\"] = str(entry.get(\"visualization_prompt\", \"\"))\n",
    "    entry[\"visualization_explanation\"] = str(entry.get(\"visualization_explanation\", \"\"))\n",
    "\n",
    "# Paso 3: Convertir la lista de diccionarios a un DataFrame de pandas\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Paso 4: Definir el esquema del dataset utilizando `Features`\n",
    "features = Features({\n",
    "    \"visualization_prompt\": Value(\"string\"),\n",
    "    \"visualization_code\": Value(\"string\"),  # Ahora es una cadena JSON\n",
    "    \"visualization_explanation\": Value(\"string\")\n",
    "})\n",
    "\n",
    "# Paso 5: Crear el objeto Dataset desde el DataFrame\n",
    "dataset_aux = Dataset.from_pandas(df, features=features, preserve_index=False)\n",
    "\n",
    "# Paso 6: Crear DatasetDict si es necesario\n",
    "dataset_2= DatasetDict({\n",
    "    \"train\": dataset_aux\n",
    "})\n",
    "\n",
    "# Verificar el contenido\n",
    "print(dataset_2)\n",
    "print(dataset_2[\"train\"][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualization_prompt': 'Create a visualization of a chart with a logarithmic color axis that supports negative values. The chart should display monthly data points ranging from negative to positive values, with a custom axis conversion to handle negative logarithmic values.', 'visualization_code': [{'html': '<div id=\"container\"></div>', 'CSS': '#container {\\n    min-width: 300px;\\n    max-width: 800px;\\n    margin: 0 auto;\\n}\\n', 'JavaScript': \"/**\\n * Custom Axis extension to allow emulation of negative values on a logarithmic\\n * color axis. Note that the scale is not mathematically correct, as a true\\n * logarithmic axis never reaches or crosses zero.\\n */\\n(function (H) {\\n    H.addEvent(H.Axis, 'afterInit', function () {\\n        const logarithmic = this.logarithmic;\\n\\n        if (logarithmic && this.options.allowNegativeLog) {\\n\\n            // Avoid errors on negative numbers on a log axis\\n            this.positiveValuesOnly = false;\\n\\n            // Override the converter functions\\n            logarithmic.log2lin = num => {\\n                const isNegative = num < 0;\\n\\n                let adjustedNum = Math.abs(num);\\n\\n                if (adjustedNum < 10) {\\n                    adjustedNum += (10 - adjustedNum) / 10;\\n                }\\n\\n                const result = Math.log(adjustedNum) / Math.LN10;\\n                return isNegative ? -result : result;\\n            };\\n\\n            logarithmic.lin2log = num => {\\n                const isNegative = num < 0;\\n\\n                let result = Math.pow(10, Math.abs(num));\\n                if (result < 10) {\\n                    result = (10 * (result - 1)) / (10 - 1);\\n                }\\n                return isNegative ? -result : result;\\n            };\\n        }\\n    });\\n}(Highcharts));\\n\\n\\nHighcharts.chart('container', {\\n\\n    title: {\\n        text: 'Logarithmic color axis with custom conversion allows negative ' +\\n            'values'\\n    },\\n\\n    xAxis: {\\n        categories: [\\n            'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\\n            'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\\n        ]\\n    },\\n\\n    colorAxis: {\\n        type: 'logarithmic',\\n        allowNegativeLog: true\\n    },\\n\\n    series: [{\\n        data: [-1000, -100, -10, -1, -0.1, 0, 0.1, 1, 10, 100, 1000]\\n    }]\\n\\n});\\n\"}], 'visualization_explanation': 'The provided JavaScript code extends the Highcharts library to allow for the emulation of negative values on a logarithmic color axis, which is not mathematically correct but serves a specific visualization need. The code overrides the default logarithmic conversion functions to handle negative numbers by adjusting them to avoid errors. The chart is then configured to use this custom axis with a series of data points ranging from negative to positive values, demonstrating the capability of the custom axis. The HTML and CSS ensure the chart is centered and responsive within a container.'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualization_prompt': \"Create a Highcharts chartOptions object to render a 3D pie chart with the following specifications: Chart type: pie, Chart title: '3D Pie Chart Example', Axes and labels styling: Use a dark blue color (#003366) for the title and labels, with a font size of 14px for labels and 18px for the title. Data series: Include one series with the data [2, 4, 6, 1, 3]. Custom colors: Use a specific list of colors ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0', '#9966FF']. Additional configurations: Set the chart margins to 50px, use a light gray background (#F5F5F5), and enable the legend with a dark gray color (#333333).\", 'visualization_code': '{\"chart\": {\"backgroundColor\": \"#F5F5F5\", \"margin\": [50, 50, 50, 50]}, \"title\": {\"text\": \"3D Pie Chart Example\", \"style\": {\"color\": \"#003366\", \"fontSize\": \"18px\"}}, \"plotOptions\": {\"pie\": {\"depth\": 45, \"startAngle\": -90, \"endAngle\": 90, \"colors\": [\"#FF6384\", \"#36A2EB\", \"#FFCE56\", \"#4BC0C0\", \"#9966FF\"]}}, \"series\": [{\"data\": [2, 4, 6, 1, 3]}], \"legend\": {\"enabled\": true, \"itemStyle\": {\"color\": \"#333333\"}}, \"xAxis\": {\"labels\": {\"style\": {\"color\": \"#003366\", \"fontSize\": \"14px\"}}}, \"yAxis\": {\"labels\": {\"style\": {\"color\": \"#003366\", \"fontSize\": \"14px\"}}}}', 'visualization_explanation': \"The provided Highcharts chartOptions object is configured to render a 3D pie chart with specific visual customizations. The chart type is set to 'pie' with 3D options enabled, creating a 3D effect with an alpha angle of 25 degrees. The chart title is styled with a dark blue color and a larger font size, while the axes labels are also styled in dark blue with a smaller font size. The data series includes one series with the values [2, 4, 6, 1, 3], and custom colors are applied to each segment of the pie chart. Additional configurations include setting the chart background to light gray and adjusting the margins to 50px. The legend is enabled and styled with a dark gray color, enhancing the overall readability and visual appeal of the chart.\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_2[\"train\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2TokenizerFast(name_or_path='unsloth/qwen2.5-coder-7b-instruct-bnb-4bit', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|PAD_TOKEN|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151665: AddedToken(\"<|PAD_TOKEN|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 983/983 [00:00<00:00, 32029.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_2 = dataset_2.map(formatting_prompts_func_2, batched=True, fn_kwargs={'tokenizer': tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched=True, fn_kwargs={'tokenizer': tokenizer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['visualization_prompt', 'visualization_code', 'visualization_explanation', 'text'],\n",
      "        num_rows: 983\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#print(dataset[\"text\"][0])\n",
    "print(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['visualization_prompt', 'visualization_code', 'visualization_explanation', 'text'],\n",
      "        num_rows: 884\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['visualization_prompt', 'visualization_code', 'visualization_explanation', 'text'],\n",
      "        num_rows: 99\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Dividir el dataset en entrenamiento y validaciÃ³n (90% train, 10% validation)\n",
    "split_dataset = dataset_2[\"train\"].train_test_split(test_size=0.1, seed=3407)\n",
    "# Crear un nuevo DatasetDict con los splits 'train' y 'validation'\n",
    "dataset_2 = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"]  # 'test' se renombra como 'validation'\n",
    "})\n",
    "print(dataset_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualization_prompt': \"Create a Highcharts chartOptions object to render a chart with the following specifications: Chart type: line and pie, Chart title: 'Series and point color index', Axes and labels styling: x-axis categories are ['Monday', 'Tuesday', 'Wednesday', 'Thursday'], y-axis title is null, Data series: 'Apples' series with data [0, -1, 1, 0], 'Oranges' series with data [1, 2, 6, 7], 'Chilis' series with data [1, 1, 3, 2], and a pie series named 'Totals' with data [{ name: 'Chilis', y: 6 }, { name: 'Oranges', y: 16 }], Custom colors: green for the first series, orange for the second, and red for the third, Additional configurations: styledMode enabled, pie series size is '30%' and centered at ['20%', '30%'].\", 'visualization_code': '{\"chart\": {\"styledMode\": true}, \"title\": {\"text\": \"Series and point color index\"}, \"xAxis\": {\"categories\": [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]}, \"yAxis\": {\"title\": {\"text\": null}}, \"series\": [{\"type\": \"line\", \"name\": \"Apples\", \"data\": [0, -1, 1, 0], \"colorIndex\": 0}, {\"type\": \"line\", \"name\": \"Oranges\", \"data\": [1, 2, 6, 7], \"colorIndex\": 1}, {\"type\": \"line\", \"name\": \"Chilis\", \"data\": [1, 1, 3, 2], \"colorIndex\": 2}, {\"type\": \"pie\", \"name\": \"Totals\", \"data\": [{\"name\": \"Chilis\", \"y\": 6, \"colorIndex\": 2}, {\"name\": \"Oranges\", \"y\": 16, \"colorIndex\": 1}], \"size\": \"30%\", \"center\": [\"20%\", \"30%\"]}]}', 'visualization_explanation': \"The provided Highcharts chartOptions object is configured to render a mixed chart with both line and pie series. The chart title is set to 'Series and point color index'. The x-axis is labeled with days of the week, and the y-axis title is null. There are three line series: 'Apples', 'Oranges', and 'Chilis', each with specified data points and color indices corresponding to green, orange, and red, respectively. Additionally, a pie series named 'Totals' is included, displaying the total values for 'Chilis' and 'Oranges' with the same color indices. The pie series is sized at 30% and positioned at the center of the chart at ['20%', '30%']. The chart is rendered in styled mode, allowing for custom CSS styling as defined in the provided CSS.\", 'text': 'Below is an instruction that give a prompt. Write a response that appropriately completes the request and gives you a visualization code and the corresponding explanation.\\n\\n### visualization _prompt:\\nCreate a Highcharts chartOptions object to render a chart with the following specifications: Chart type: line and pie, Chart title: \\'Series and point color index\\', Axes and labels styling: x-axis categories are [\\'Monday\\', \\'Tuesday\\', \\'Wednesday\\', \\'Thursday\\'], y-axis title is null, Data series: \\'Apples\\' series with data [0, -1, 1, 0], \\'Oranges\\' series with data [1, 2, 6, 7], \\'Chilis\\' series with data [1, 1, 3, 2], and a pie series named \\'Totals\\' with data [{ name: \\'Chilis\\', y: 6 }, { name: \\'Oranges\\', y: 16 }], Custom colors: green for the first series, orange for the second, and red for the third, Additional configurations: styledMode enabled, pie series size is \\'30%\\' and centered at [\\'20%\\', \\'30%\\'].\\n\\n### visualization_code:\\n{\"chart\": {\"styledMode\": true}, \"title\": {\"text\": \"Series and point color index\"}, \"xAxis\": {\"categories\": [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\"]}, \"yAxis\": {\"title\": {\"text\": null}}, \"series\": [{\"type\": \"line\", \"name\": \"Apples\", \"data\": [0, -1, 1, 0], \"colorIndex\": 0}, {\"type\": \"line\", \"name\": \"Oranges\", \"data\": [1, 2, 6, 7], \"colorIndex\": 1}, {\"type\": \"line\", \"name\": \"Chilis\", \"data\": [1, 1, 3, 2], \"colorIndex\": 2}, {\"type\": \"pie\", \"name\": \"Totals\", \"data\": [{\"name\": \"Chilis\", \"y\": 6, \"colorIndex\": 2}, {\"name\": \"Oranges\", \"y\": 16, \"colorIndex\": 1}], \"size\": \"30%\", \"center\": [\"20%\", \"30%\"]}]}\\n\\n### visualization_explanation:\\nThe provided Highcharts chartOptions object is configured to render a mixed chart with both line and pie series. The chart title is set to \\'Series and point color index\\'. The x-axis is labeled with days of the week, and the y-axis title is null. There are three line series: \\'Apples\\', \\'Oranges\\', and \\'Chilis\\', each with specified data points and color indices corresponding to green, orange, and red, respectively. Additionally, a pie series named \\'Totals\\' is included, displaying the total values for \\'Chilis\\' and \\'Oranges\\' with the same color indices. The pie series is sized at 30% and positioned at the center of the chart at [\\'20%\\', \\'30%\\']. The chart is rendered in styled mode, allowing for custom CSS styling as defined in the provided CSS.<|im_end|>'}\n",
      "{'visualization_prompt': \"Create a Highcharts chartOptions object to render a bar chart with the following specifications: Chart type: bar, Chart title: 'Monthly Revenue Analysis', Axes and labels styling: Use a dark theme with white text for labels and titles, Data series: Two series named 'Revenue 2022' and 'Revenue 2023' with corresponding data, Custom colors: Use a gradient from blue to green, Additional configurations: Set chart margins, background, and legend position.\", 'visualization_code': '{\"chart\": {\"animation\": false, \"type\": \"bar\", \"backgroundColor\": \"#2c3e50\", \"marginTop\": 60, \"marginBottom\": 100}, \"title\": {\"text\": \"Monthly Revenue Analysis\", \"style\": {\"color\": \"#ffffff\", \"fontSize\": \"20px\"}}, \"xAxis\": {\"categories\": [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], \"labels\": {\"style\": {\"color\": \"#ffffff\"}}}, \"yAxis\": {\"softMin\": -200, \"softMax\": 400, \"title\": {\"text\": \"Revenue\", \"style\": {\"color\": \"#ffffff\"}}, \"labels\": {\"style\": {\"color\": \"#ffffff\"}}}, \"plotOptions\": {\"series\": {\"stickyTracking\": false, \"dragDrop\": {\"draggableY\": true}, \"states\": {\"inactive\": {\"opacity\": 1}}}, \"bar\": {\"stacking\": \"normal\", \"minPointLength\": 2, \"colorByPoint\": true, \"colors\": [\"#007acc\", \"#0099cc\", \"#00b3cc\", \"#00ccb3\", \"#00cc99\", \"#00cc7a\", \"#00cc5c\", \"#00cc3d\", \"#00cc1f\", \"#00cc00\"]}}, \"tooltip\": {\"valueDecimals\": 2}, \"legend\": {\"itemStyle\": {\"color\": \"#ffffff\"}, \"itemHoverStyle\": {\"color\": \"#dddddd\"}, \"itemHiddenStyle\": {\"color\": \"#444444\"}, \"align\": \"right\", \"verticalAlign\": \"top\"}, \"series\": [{\"name\": \"Revenue 2022\", \"data\": [0, 71.5, -106.4, 129.2, 144.0, 176.0, 135.6, 148.5, 216.4, 194.1, -95.6, 54.4]}, {\"name\": \"Revenue 2023\", \"data\": [0, -71.5, 106.4, 129.2, 144.0, 176.0, 135.6, 148.5, 216.4, 194.1, 95.6, 54.4]}]}', 'visualization_explanation': \"The provided Highcharts chartOptions object is configured to render a bar chart with a dark theme, suitable for a monthly revenue analysis. The chart title is styled with white text and a larger font size for better visibility. The x-axis and y-axis labels, along with their titles, are also styled in white to contrast with the dark background. The chart includes two data series, 'Revenue 2022' and 'Revenue 2023', each with corresponding monthly data. The bars are colored using a gradient from blue to green, enhancing visual distinction. Additional configurations include setting the chart margins for better spacing and positioning the legend at the top-right corner for easy access. The chart is designed to be visually appealing and informative, making it suitable for financial or business analytics.\", 'text': 'Below is an instruction that give a prompt. Write a response that appropriately completes the request and gives you a visualization code and the corresponding explanation.\\n\\n### visualization _prompt:\\nCreate a Highcharts chartOptions object to render a bar chart with the following specifications: Chart type: bar, Chart title: \\'Monthly Revenue Analysis\\', Axes and labels styling: Use a dark theme with white text for labels and titles, Data series: Two series named \\'Revenue 2022\\' and \\'Revenue 2023\\' with corresponding data, Custom colors: Use a gradient from blue to green, Additional configurations: Set chart margins, background, and legend position.\\n\\n### visualization_code:\\n{\"chart\": {\"animation\": false, \"type\": \"bar\", \"backgroundColor\": \"#2c3e50\", \"marginTop\": 60, \"marginBottom\": 100}, \"title\": {\"text\": \"Monthly Revenue Analysis\", \"style\": {\"color\": \"#ffffff\", \"fontSize\": \"20px\"}}, \"xAxis\": {\"categories\": [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], \"labels\": {\"style\": {\"color\": \"#ffffff\"}}}, \"yAxis\": {\"softMin\": -200, \"softMax\": 400, \"title\": {\"text\": \"Revenue\", \"style\": {\"color\": \"#ffffff\"}}, \"labels\": {\"style\": {\"color\": \"#ffffff\"}}}, \"plotOptions\": {\"series\": {\"stickyTracking\": false, \"dragDrop\": {\"draggableY\": true}, \"states\": {\"inactive\": {\"opacity\": 1}}}, \"bar\": {\"stacking\": \"normal\", \"minPointLength\": 2, \"colorByPoint\": true, \"colors\": [\"#007acc\", \"#0099cc\", \"#00b3cc\", \"#00ccb3\", \"#00cc99\", \"#00cc7a\", \"#00cc5c\", \"#00cc3d\", \"#00cc1f\", \"#00cc00\"]}}, \"tooltip\": {\"valueDecimals\": 2}, \"legend\": {\"itemStyle\": {\"color\": \"#ffffff\"}, \"itemHoverStyle\": {\"color\": \"#dddddd\"}, \"itemHiddenStyle\": {\"color\": \"#444444\"}, \"align\": \"right\", \"verticalAlign\": \"top\"}, \"series\": [{\"name\": \"Revenue 2022\", \"data\": [0, 71.5, -106.4, 129.2, 144.0, 176.0, 135.6, 148.5, 216.4, 194.1, -95.6, 54.4]}, {\"name\": \"Revenue 2023\", \"data\": [0, -71.5, 106.4, 129.2, 144.0, 176.0, 135.6, 148.5, 216.4, 194.1, 95.6, 54.4]}]}\\n\\n### visualization_explanation:\\nThe provided Highcharts chartOptions object is configured to render a bar chart with a dark theme, suitable for a monthly revenue analysis. The chart title is styled with white text and a larger font size for better visibility. The x-axis and y-axis labels, along with their titles, are also styled in white to contrast with the dark background. The chart includes two data series, \\'Revenue 2022\\' and \\'Revenue 2023\\', each with corresponding monthly data. The bars are colored using a gradient from blue to green, enhancing visual distinction. Additional configurations include setting the chart margins for better spacing and positioning the legend at the top-right corner for easy access. The chart is designed to be visually appealing and informative, making it suitable for financial or business analytics.<|im_end|>'}\n"
     ]
    }
   ],
   "source": [
    "# Verificar una muestra del split de entrenamiento\n",
    "print(dataset_2[\"train\"][0])\n",
    "\n",
    "# Verificar una muestra del split de validaciÃ³n\n",
    "print(dataset_2[\"validation\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 884/884 [00:00<00:00, 35152.69 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:00<00:00, 23220.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n",
      "['text']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el formateo al split de entrenamiento\n",
    "dataset_2[\"train\"] = dataset_2[\"train\"].map(\n",
    "    formatting_prompts_func_2,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': tokenizer},\n",
    "    remove_columns=[\"visualization_prompt\", \"visualization_code\", \"visualization_explanation\"]\n",
    "    if all(col in dataset_2[\"train\"].column_names for col in [\"visualization_prompt\", \"visualization_code\", \"visualization_explanation\"])\n",
    "    else None\n",
    ")\n",
    "\n",
    "# Aplicar el formateo al split de validaciÃ³n\n",
    "dataset_2[\"validation\"] = dataset_2[\"validation\"].map(\n",
    "    formatting_prompts_func_2,\n",
    "    batched=True,\n",
    "    fn_kwargs={'tokenizer': tokenizer},\n",
    "    remove_columns=[\"visualization_prompt\", \"visualization_code\", \"visualization_explanation\"]\n",
    "    if all(col in dataset_2[\"validation\"].column_names for col in [\"visualization_prompt\", \"visualization_code\", \"visualization_explanation\"])\n",
    "    else None\n",
    ")\n",
    "print(dataset_2[\"train\"].column_names)\n",
    "print(dataset_2[\"validation\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 884/884 [00:01<00:00, 733.30 examples/s]\n",
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:00<00:00, 138.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Definir los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 2,                # TamaÃ±o del batch por dispositivo\n",
    "    gradient_accumulation_steps = 1,                # Acumular gradientes durante 2 pasos\n",
    "    warmup_steps = 190,                             # NÃºmero de pasos de warmup es entre un 1% y 10% del total de pasos\n",
    "    num_train_epochs=3,                             #Descomenta y ajusta si prefieres usar Ã©pocas en lugar de max_steps\n",
    "    #max_steps = 60,                                # NÃºmero mÃ¡ximo de pasos de entrenamiento\n",
    "    learning_rate = 2e-5,                           # Tasa de aprendizaje\n",
    "    fp16 = not is_bfloat16_supported(),             # Usar FP16 si BFLOAT16 no es soportado\n",
    "    bf16 = is_bfloat16_supported(),                 # Usar BFLOAT16 si es soportado\n",
    "    logging_steps = 50,                             # Registrar cada paso\n",
    "    save_steps=500,                                 # Guarda el modelo cada 1000 pasos\n",
    "    optim = \"adamw_8bit\",                           # Optimizador AdamW con 8-bit\n",
    "    weight_decay = 0.01,                            # Decaimiento de peso\n",
    "    lr_scheduler_type = \"linear\",                   # Tipo de scheduler de LR\n",
    "    seed = 3407,                                    # Semilla para reproducibilidad\n",
    "    output_dir = \"outputs\",                         # Directorio de salida\n",
    ")\n",
    "\n",
    "# Crear el entrenador\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset_2[\"train\"],  # Usar el split de entrenamiento\n",
    "    eval_dataset=dataset_2[\"validation\"],  # Usar el split de validaciÃ³n\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,                       # NÃºmero de procesos para el dataset\n",
    "    packing = False,                             # Desactivar packing si no es necesario\n",
    "    args = training_args,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Definir los argumentos de entrenamiento ajustados\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,                # Reducido de 2 a 1\n",
    "    gradient_accumulation_steps=8,                # Ajustado para mantener el tamaÃ±o de batch efectivo\n",
    "    warmup_steps=175,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    fp16 = not is_bfloat16_supported(),  # Auto-ajustar segÃºn hardware\n",
    "    bf16 = is_bfloat16_supported(),                                 # Desactivar BF16\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\", # antes --> cosine\n",
    "    seed=3407,\n",
    "    output_dir=\"outputs\",\n",
    "    gradient_checkpointing=False,\n",
    "    max_grad_norm= 0.3  # Desactivar clipping de gradiente\n",
    ")\n",
    "\n",
    "\n",
    "# Crear el entrenador con los splits especÃ­ficos y el data collator personalizado\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset_2[\"train\"],            # Usar el split de entrenamiento\n",
    "    eval_dataset=dataset_2[\"validation\"],        # Usar el split de validaciÃ³n\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3080. Max memory = 9.765 GB.\n",
      "5.258 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParÃ¡metros entrenables: 10092544\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ParÃ¡metros entrenables: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 884 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 8\n",
      "\\        /    Total batch size = 8 | Total steps = 330\n",
      " \"-____-\"     Number of trainable parameters = 10,092,544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 34:08, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.418500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iniciar el entrenamiento\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056.3963 seconds used for training.\n",
      "34.27 minutes used for training.\n",
      "Peak reserved memory = 6.648 GB.\n",
      "Peak reserved memory for training = 1.39 GB.\n",
      "Peak reserved memory % of max memory = 68.08 %.\n",
      "Peak reserved memory for training % of max memory = 14.235 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 3584, padding_idx=151665)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Poner el modelo en modo de evaluaciÃ³n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 3584, padding_idx=151665)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Configurar el modelo en modo de inferencia\n",
    "FastLanguageModel.for_inference(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_visualization_code(prompt):\n",
    "    # Tokenizar el prompt de entrada\n",
    "    text = \"It responds in JSON format with two attributes the name of the attributes must being visualization_code and visualization_explanation, in visualization_code it only writes a chartOptions object from HighchartJS and in visualization_explanation it only writes the chart's explanation.\\n\"\n",
    "    \"\"\"JSON example expected:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"visualization_code\": { /* chartOptions object */ },\\n'\n",
    "        '  \"visualization_explanation\": \"Tu explicaciÃ³n aquÃ­.\"\\n'\n",
    "        \"}\\n\"\"\" f\"{prompt}\\n\" \n",
    "    \"Response:\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")  # AsegÃºrate de que el modelo estÃ© en la GPU\n",
    "    # Determinar la longitud mÃ¡xima permitida\n",
    "    max_seq_length = model.config.max_position_embeddings or 1024\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    available_tokens = max_seq_length - input_length - 10  # Reservar algunos tokens\n",
    "\n",
    "    max_new_tokens = min(800, available_tokens)  # Ajustar segÃºn tus necesidades\n",
    "    # Generar la respuesta del modelo\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,            # MÃ¡xima longitud de la respuesta generada\n",
    "            max_length = 1024,\n",
    "            do_sample=False,                # Activar muestreo para generar variedad en las respuestas\n",
    "            top_k=20,                      # Usar top-k sampling para controlar la diversidad\n",
    "            top_p=0.9,                    # Usar nucleus sampling\n",
    "            temperature=0.7,               # Controlar la creatividad en la generaciÃ³n\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Decodificar el resultado a texto\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"Response:\" in response:\n",
    "            response = response.split(\"Response:\")[1].strip()\n",
    "            \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_visualization_code(prompt):\n",
    "    system_message = (\n",
    "        \"It responds in JSON format with two attributes:\\n\"\n",
    "        \" - 'visualization_code': must contain only the chartOptions object from HighchartJS.\\n\"\n",
    "        \" - 'visualization_explanation': must contain only the explanation of the chart.\\n\\n\"\n",
    "        \"Please follow exactly that JSON structure without extra text.\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    # Construye el texto final donde incluyes tu prompt y la palabra \"Response:\" \n",
    "    text = f\"{system_message}Prompt:\\n{prompt}\\n\\nResponse:\\n\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # AquÃ­, como quieres variedad, pon do_sample=True\n",
    "    # Y ajusta tus parÃ¡metros de decodificaciÃ³n\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=920,\n",
    "            do_sample=True,                # Para que haga muestreo\n",
    "            top_k=40, \n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            repetition_penalty=1.2,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Si quieres cortar justo despuÃ©s de \"Response:\", lo puedes hacer.\n",
    "    # En tu ejemplo, dices que luego parseas el JSON. \n",
    "    # Con que la salida sea consistente, basta.\n",
    "    if \"Response:\" in response:\n",
    "        response = response.split(\"Response:\")[1].strip()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1\n",
    "prompt_1 = \"Create a visualization that displays a stock chart for the company AAPL with a tooltip showing the stock price and a y-axis in percentage.\"\n",
    "\n",
    "# Ejemplo 2\n",
    "prompt_2 = \"Generate a bar chart showing the sales performance of products A, B, and C with labels for each bar.\"\n",
    "\n",
    "# Ejemplo 3\n",
    "prompt_3 = \"Create a line chart for website traffic over time, with data points for each week and tooltips displaying the visitor count.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta para prompt 1:\n",
      "{\n",
      "  \"visualization_code\": {\n",
      "    \"tooltip\": {\n",
      "      \"valueDecimals\": 2,\n",
      "      \"pointFormat\": \"<b>{series.name}</b><br/>Price: ${y:.2f}\"\n",
      "    },\n",
      "    \"xAxis\": {\n",
      "      \"type\": \"datetime\",\n",
      "      \"labels\": {\n",
      "        \"format\": \"{value:%B %e, '%Y'}\"\n",
      "      }\n",
      "    },\n",
      "    \"plotOptions\": {\n",
      "      \"area\": {\n",
      "        \"fillOpacity\": 0.5\n",
      "      }\n",
      "    },\n",
      "    \"rangeSelector\": {\n",
      "      \"selected\": 4\n",
      "    },\n",
      "    \"title\": {\n",
      "      \"text\": \"AAPL Stock Price\"\n",
      "    },\n",
      "    \"subtitle\": {\n",
      "      \"text\": \"Source: <a href='https://www.alphavantage.co/'>Alpha Vantage</a>\"\n",
      "    },\n",
      "    \"legend\": {\n",
      "      \"enabled\": true\n",
      "    },\n",
      "    \"credits\": {\n",
      "      \"href\": \"http://www.highcharts.com/\",\n",
      "      \"text\": \"\\u00A9 Highsoft AS\"\n",
      "    },\n",
      "    \"series\": [\n",
      "      {\n",
      "        \"name\": \"AAPL\",\n",
      "        \"data\": [],\n",
      "        \"colorByPoint\": false,\n",
      "        \"negativeColor\": \"#ff3d81\",\n",
      "        \"zoneAxis\": \"y\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"visualization_explanation\": \"The provided Highcharts configuration is designed to display a dynamic stock chart focusing on the Apple Inc. (AAPL) stock over time. The chart includes tooltips that show both the name of the series ('AAPL') and its corresponding stock price formatted as currency. The x-axis represents dates, formatted to include month names and year abbreviations. A range selector allows users to quickly jump between different timeframes, defaulting to the last four days. Additional features like axis titles, subtitle, legend, and credits are included to enhance user interaction and understanding.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Respuesta para prompt 1:\")\n",
    "print(generate_visualization_code(prompt_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta para prompt 2:\n",
      "{\n",
      "  \"visualization_code\": {\n",
      "    \"chart\": {\n",
      "      \"type\": \"bar\"\n",
      "    },\n",
      "    \"title\": {\n",
      "      \"text\": \"Sales Performance of Products A, B, and C\",\n",
      "      \"style\": {\n",
      "        \"fontSize\": \"18px\"\n",
      "      }\n",
      "    },\n",
      "    \"xAxis\": {\n",
      "      \"categories\": [\"Product A\", \"Product B\", \"Product C\"],\n",
      "      \"labels\": {\n",
      "        \"rotation\": 0,\n",
      "        \"y\": 36\n",
      "      }\n",
      "    },\n",
      "    \"yAxis\": {\n",
      "      \"min\": 0,\n",
      "      \"maxPadding\": 0.2,\n",
      "      \"title\": {\n",
      "        \"align\": \"high\",\n",
      "        \"offset\": 0,\n",
      "        \"floating\": true,\n",
      "        \"formatters\": null,\n",
      "        \"useHTML\": false,\n",
      "        \"margin\": 45,\n",
      "        \"radian\": false,\n",
      "        \"gridLineWidth\": 0,\n",
      "        \"left\": null,\n",
      "        \"right\": null,\n",
      "        \"top\": null,\n",
      "        \"bottom\": null,\n",
      "        \"textAlign\": \"\",\n",
      "        \"verticalAlign\": \"\"\n",
      "      },\n",
      "      \"title\": {\n",
      "        \"text\": \"Units sold\",\n",
      "        \"style\": {\n",
      "          \"color\": \"#000000\",\n",
      "          \"fontWeight\": \"bold\",\n",
      "          \"fontFamily\": \"'Open Sans', sans-serif\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"tooltip\": {},\n",
      "    \"plotOptions\": {\n",
      "      \"series\": {\n",
      "        \"stacking\": \"normal\",\n",
      "        \"dataLabels\": {\n",
      "          \"enabled\": true,\n",
      "          \"format\": \"{point.y:.2f}\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"legend\": {\n",
      "      \"reversed\": true,\n",
      "      \"layout\": \"horizontal\",\n",
      "      \"align\": \"center\",\n",
      "      \"itemMarginTop\": 7,\n",
      "      \"symbolHeight\": 3,\n",
      "      \"borderWidth\": 1,\n",
      "      \"labelFormatter\": function() {\n",
      "        return this.name;\n",
      "      },\n",
      "      \"shadow\": false,\n",
      "      \"backgroundColor\": \"#FFFFFF\",\n",
      "      \"alignColumns\": false,\n",
      "      \"itemDistance\": 10,\n",
      "      \"width\": undefined,\n",
      "      \"padding\": 8,\n",
      "      \"valueDecimals\": 2,\n",
      "      \"marker\": {\n",
      "        \"radius\": 1,\n",
      "        \"states\": {}\n",
      "      },\n",
      "      \"symbolRadius\": 0,\n",
      "      \"itemStyle\": {\n",
      "        \"overflow\": \"hidden\"\n",
      "      },\n",
      "      \"gutter\": 1,\n",
      "      \"itemHoverStyle\": {\n",
      "        \"fillOpacity\": 1\n",
      "      }\n",
      "    },\n",
      "    \"credits\": {\n",
      "      \"enabled\": false\n",
      "    },\n",
      "    \"colors\": [\n",
      "      \"#FABD24\",\n",
      "      \"#FF9C9A\",\n",
      "      \"#9BC2EB\"\n",
      "    ],\n",
      "    \"series\": [\n",
      "      {\n",
      "        \"name\": \"Series 1\",\n",
      "        \"data\": [null]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Series 2\",\n",
      "        \"data\": [null]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"visualization_explanation\": \"This bar chart displays the sales performance of three products: Product A, Product B, and Product C. The x-axis represents the different products, while the y-axis shows the units sold. Each bar is labeled directly above it to indicate the exact value.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRespuesta para prompt 2:\")\n",
    "print(generate_visualization_code(prompt_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta para prompt 2:\n",
      "{\n",
      "  \"visualization_code\": {\n",
      "    \"chart\": {\n",
      "      \"type\": \"bar\"\n",
      "    },\n",
      "    \"title\": {\n",
      "      \"text\": \"Sales Performance of Products\"\n",
      "    },\n",
      "    \"xAxis\": {\n",
      "      \"categories\": [\"Product A\", \"Product B\", \"Product C\"],\n",
      "      \"labels\": {\n",
      "        \"enabled\": true\n",
      "      }\n",
      "    },\n",
      "    \"yAxis\": {\n",
      "      \"min\": 0,\n",
      "      \"maxPadding\": 0.15,\n",
      "      \"tickInterval\": 2,\n",
      "      \"minorTickLength\": 3,\n",
      "      \"endOnTick\": false,\n",
      "      \"showLastLabel\": true\n",
      "    },\n",
      "    \"legend\": {\n",
      "      \"align\": \"right\",\n",
      "      \"layout\": \"vertical\",\n",
      "      \"backgroundColor\": \"#FFFFFF\",\n",
      "      \"floating\": true,\n",
      "      \"reversed\": true,\n",
      "      \"shadow\": true,\n",
      "      \"x\": 400,\n",
      "      \"y\": 70,\n",
      "      \"marker\": {\n",
      "        \"symbol\": \"square\"\n",
      "      }\n",
      "    },\n",
      "    \"credits\": {\n",
      "      \"enabled\": false\n",
      "    },\n",
      "    \"plotOptions\": {\n",
      "      \"series\": {\n",
      "        \"stacking\": null,\n",
      "        \"dataLabels\": {\n",
      "          \"enabled\": true,\n",
      "          \"format\": \"{point.y}%\",\n",
      "          \"style\": {\n",
      "            \"color\": \"(Highcharts.theme && Highcharts.theme.dataLabelsColor) || data.label.color\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"tooltip\": {\n",
      "      \"shared\": true\n",
      "    },\n",
      "    \"colors\": [\n",
      "      \"#F6895D\",\n",
      "      \"#C8E0A9\",\n",
      "      \"#FFBEBE\"\n",
      "    ],\n",
      "    \"series\": [\n",
      "      {\n",
      "        \"name\": \"Performance\",\n",
      "        \"data\": [12.5, 22.5, 15]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"visualization_explanation\": \"This bar chart displays the sales performance of three products: Product A, Product B, and Product C. Each product is represented by a bar with corresponding percentages shown on top of each bar.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRespuesta para prompt 2:\")\n",
    "print(generate_visualization_code(prompt_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta para prompt 3:\n",
      "{\n",
      "  \"visualization_code\": {\n",
      "    \"title\": {\"text\": \"Website Traffic Over Time\"},\n",
      "    \"xAxis\": {\"categories\": [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\"]},\n",
      "    \"yAxis\": {\"min\": 0, \"title\": {\"text\": null}},\n",
      "    \"series\": [{\"name\": \"Visitor Count\", \"data\": [500, 750, 689, 577]}],\n",
      "    \"tooltip\": {\"valueSuffix\": \"<br/>visitors\"}\n",
      "  },\n",
      "  \"visualization_explanation\": \"This line chart displays the website traffic over four weeks. The x-axis represents different weeks, while the y-axis shows the number of visitors. Each point on the line corresponds to the visitor count for that specific week.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRespuesta para prompt 3:\")\n",
    "print(generate_visualization_code(prompt_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta para prompt 4:\n",
      "{\n",
      "\"visualization_code\": {\n",
      "\"xAxis\": {\"categories\": [\"IBM\", \"Microsoft\", \"Tesla\", \"OpenAI\"]},\n",
      "\"title\": {\"text\": \"Average Revenue Per Year by Company\"},\n",
      "\"yAxis\": {\"title\": {\"text\": \"Revenue ($)\"}, \"labels\": {\"format\": \"{value}\"}},\n",
      "\"series\": [{\"data\": [30000000, 60000000, 150000000, 200000000], \"type\": \"bar\"}]\n",
      "},\n",
      "\"visualization_explanation\": \"This bar chart displays the average revenue generated by four major technology companies: IBM, Microsoft, Tesla, and OpenAI. The x-axis represents the companies, while the y-axis shows their respective revenues in dollars. Each company is represented by a bar, making it easy to compare their performance at a glance.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_4 = \"\"\"I want you to generate a bar visualisation for the following companies and how much on average it generates per year:\n",
    "IBM = 30000000$.\n",
    "Microsoft = 60000000$.\n",
    "Tesla = 150000000$.\n",
    "OpenAI = 200000000$.\"\"\"\n",
    "print(\"\\nRespuesta para prompt 4:\")\n",
    "print(generate_visualization_code(prompt_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = \"HOW MUCH IT IS: 2 + 2 ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta para prompt 5:\n",
      "{\n",
      "\"visualization_code\": {\n",
      "    \"title\": {\"text\": \"How much is 2 + 2?\"},\n",
      "    \"xAxis\": {\"categories\": [\"Result\"]},\n",
      "    \"yAxis\": {\"labels\": {\"format\": \"{value}\"}},\n",
      "    \"series\": [{\"data\": [4]}]\n",
      "},\n",
      "\"visualization_explanation\": \"This bar chart shows the result of adding 2 and 2, which is 4.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRespuesta para prompt 5:\")\n",
    "print(generate_visualization_code(prompt_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./modelo_v1/tokenizer_config.json',\n",
       " './modelo_v1/special_tokens_map.json',\n",
       " './modelo_v1/vocab.json',\n",
       " './modelo_v1/merges.txt',\n",
       " './modelo_v1/added_tokens.json',\n",
       " './modelo_v1/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./QLoRA_Qwenn_14B\")\n",
    "tokenizer.save_pretrained(\"./QLoRA_Qwenn_14B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
